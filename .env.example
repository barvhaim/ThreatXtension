# **** LLM (Large Language Model) configuration ****
LLM_PROVIDER=watsonx  # Options: ollama, watsonx, rits, openai
LLM_MODEL=meta-llama/llama-3-3-70b-instruct

# * watsonx.ai configuration if LLM_PROVIDER is set to 'watsonx'
WATSONX_URL=https://us-south.ml.cloud.ibm.com/
WATSONX_APIKEY=
WATSONX_PROJECT_ID=
WX_PROJECT_ID=

# * RITS configuration if LLM_PROVIDER is set to 'rits' (Internal IBM Research service)
RITS_API_KEY=
RITS_API_BASE_URL=

# * Langsmith configuration
LANGSMITH_TRACING=false
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=

# * Extensions
CHROME_VERSION=118.0
EXTENSION_STORAGE_PATH=./extensions_storage
